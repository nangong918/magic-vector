**设计思路**
============

## 基本功能

App创建聊天Agent, 做出特殊设定, 包括AI记忆, Agent可以注入到嵌入式设备 (MCP)
嵌入式设备可以进行本地函数调用, 如: 移动, 视觉, 传感, 询问.
设备本身有基础Agent, 包括上述函数调用的功能, 是自发的, 用户不可控的
语音转文字stt功能
AI文本转语音tts功能
部署服务器远程控制(Iot)
Spring, Android, Esp32 三端长连接互通控制

## 功能详情

### Agent模块

* 创建Agent
  * Android：
    * 设置Agent名称，Agent系统级别描述设定，设置Agent头像，提交Agent创建 
    * （后续升级：获取并设置Agent声音模型(tts), 设置Agent声音模型）
  * Spring：
    * 创建Agent: file文件存储minio，设定存储mysql
    * 后续升级: 接入tts模型，提供tts模型列表

* 获取最近聊天的Agent List
  * Android：
    * init：初次、再次长连接之后进行Http请求服务器，获取最新的chatList
    * 其余时候：从Room获取数据，从MMKV获取json对象数据
  * Spring：
    * init：MessageList，切面是mapper层，执行前后执行Redis查询和缓存。
* 获取跟Agent的最近的聊天记录
  * Android
    * init：初次、再次长连接之后进行Http请求服务器，获取最新的chatList
    * 后续：sse / websocket
  * Spring：
    * init：AOP获取ChatList，切面是mapper层，执行前后执行Redis查询和缓存。

### Chat模块
* 选择 / 创建 session 进行聊天
  * Android：
    * 发送sse请求
  * Spring：
    * 获取最近的ChatList组成ChatMemory + 当前消息交给AI模型，返回结果给前端

## 整体架构

### Spring设计

* 数据库
  PostgreSQL(TimeScaleDB), Neo4j, ElasticSearch, Milvus
* 缓存
  Redis
* 网络请求

WebFlux

* 长连接

前端长连接: Netty

嵌入式长连接: MQTT

* 异步

JDK21虚拟线程 (避免线程池 + 分布式)

* Oss存储

minio

* 语音通话: WebRTC(内部自带VAD)

* 音频处理
stt和tts: 阿里百炼

* 物联网监控
暂选WebRTC; 升级选择RTMP
视频编码调整 -> 视频的效果

#### AI设计

使用SpringAI框架, 快速集成ChatModel

* 联网功能
  集成`阿里百炼`的访问互联网MCP

* 聊天记忆
意图 + 实体识别 -> 成功识别 -> 结构化匹配. 
                 识别失败 -> 向量索引.


短期记忆存储Redis \ ChatMemory
长期记忆存储数据库


### 客户端设计
Jetpack Compose Android 

* 界面
Jetpack Compose混合XML

* 长连接 (Todo: 列出为什么使用Netty和Mqtt)

后端长连接: Netty

嵌入式端长连接: MQTT (IOT) 远程唤醒, 视频监控

* 设计模式

Mvvm设计模式, LiveData更新View

* 异步

Kotlin 协程

* 缓存

MMKV\SharePrefence -> View数据

Room(SQLite) -> 聊天记录

* 网络请求

TCP\IP
流式Http传输

OKhttp\Retrofit

* 语音通话
WebRTC

* 物联网视频监控
暂时选用WebRTC, 升级选择RTMP

### 嵌入式设计

* 开发板

ESP32-SC

* 屏幕
* 音频录制\发出
* 运动舵机
* 传感器
* 摄像头

### 服务部署

* Docker
* Kubernetes(K8s)
* 阿里云服务器
* Nginx反向代理域名和minio内部资源

### 注意
开发的时候需要先进行App混淆和Spring部署测试
